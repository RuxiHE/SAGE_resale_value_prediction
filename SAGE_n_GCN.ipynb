{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amYFH1lh2FG1",
        "outputId": "ae5af20b-ec5c-40dc-c876-203d1f59e4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ar4zwO8NBHS"
      },
      "source": [
        "# Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD9ugyDxNV4-",
        "outputId": "03144172-909f-4303-be6d-6cb6999b1008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O8Mf_cG6NBHU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATv2Conv, SAGEConv\n",
        "import networkx as nx\n",
        "import torch.nn as nn\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from tqdm.notebook import tqdm as tqdm_notebook\n",
        "from scipy.sparse import coo_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-EwuLufNBHV"
      },
      "source": [
        "# Preprocess data for GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l-MlMxMGNBHV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/Shareddrives/MLNS/final project/processed_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EXc1pW02FG4"
      },
      "source": [
        "Sampling 5% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpjuKfuYvo-k",
        "outputId": "c323a3dc-c34f-43c2-cc49-2d5df786eef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-2ea9598d5df1>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('brand_cleaned', group_keys=False).apply(lambda x: x.sample(frac=0.05, random_state=42)).reset_index(drop=True)\n"
          ]
        }
      ],
      "source": [
        "# Group by brand and sample 5% within each group\n",
        "df = df.groupby('brand_cleaned', group_keys=False).apply(lambda x: x.sample(frac=0.05, random_state=42)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aye1UZm2FG4"
      },
      "source": [
        "Targeted Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qkqc_lLuTH7P"
      },
      "outputs": [],
      "source": [
        "features = [\"product_type\", \"product_gender_target\",\n",
        "            \"product_material\", \"product_color\",\n",
        "            \"brand_name\", \"product_condition\", \"product_like_count\"]\n",
        "target = \"price_usd\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ru9RzDNBHW"
      },
      "source": [
        "## Feature Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QDP9WpQUNBHW"
      },
      "outputs": [],
      "source": [
        "categorical_features = [\"product_gender_target\", \"product_color\",  \"product_condition\", \"brand_cleaned\", \"material_cleaned\", \"broad_type\"]\n",
        "numerical_features = [\"product_like_count\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiL-U00eNBHW"
      },
      "source": [
        "One-Hot Encoding for categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ek1boKC6NBHW"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "categorical_encoded = encoder.fit_transform(df[categorical_features])\n",
        "categorical_cols = encoder.get_feature_names_out(categorical_features)\n",
        "categorical_df = pd.DataFrame(categorical_encoded, columns=categorical_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqQW_dBVNBHW"
      },
      "source": [
        "Standaradization for numerical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ypLMNVAvNBHX"
      },
      "outputs": [],
      "source": [
        "stdscaler = StandardScaler()\n",
        "std_features = stdscaler.fit_transform(df[numerical_features])\n",
        "numerical_df = pd.DataFrame(std_features, columns=numerical_features).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1l3ypgc2FG5"
      },
      "source": [
        "Concatenate numerical and categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q-_hh_u1NBHX"
      },
      "outputs": [],
      "source": [
        "numerical_df_aligned = numerical_df.reset_index(drop=True)\n",
        "categorical_df_aligned = categorical_df.reset_index(drop=True)\n",
        "target_df = pd.DataFrame(df[target]).reset_index(drop=True)\n",
        "df_finals = pd.concat([numerical_df_aligned, categorical_df_aligned, target_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4wpLJj9NBHX"
      },
      "source": [
        "## Transfrom to Graph-Ready Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGfVVJqaTSV6",
        "outputId": "2a540dbf-fd4d-4c01-9bd9-8761f435167b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14637, 112)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_finals.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pHfdxCkjXUc5"
      },
      "outputs": [],
      "source": [
        "# Convert input features and target\n",
        "x = torch.from_numpy(df_finals.drop(columns=[target]).values).float() # convert to float tensor\n",
        "y = torch.from_numpy(df_finals[target].values).float().view(-1, 1) # reshape to 2D tensor\n",
        "\n",
        "num_nodes, row_indices, col_indices = len(df_finals), [], []\n",
        "\n",
        "\n",
        "# Utility function to add edges from one-hot feature blocks\n",
        "def add_edges_by_feature_block(column_block, max_nodes=1000):\n",
        "    for col in column_block:\n",
        "        indices = np.flatnonzero(df_finals[col].values)\n",
        "        if len(indices) > max_nodes:\n",
        "            indices = indices[:max_nodes]\n",
        "        if len(indices) < 2:\n",
        "            continue\n",
        "        rows, cols = np.meshgrid(indices, indices)\n",
        "        mask = rows != cols\n",
        "        row_indices.extend(rows[mask].flatten())\n",
        "        col_indices.extend(cols[mask].flatten())\n",
        "\n",
        "# Collect one-hot encoded feature columns\n",
        "material_cols = [col for col in df_finals.columns if col.startswith('material_cleaned_')]\n",
        "category_cols = [col for col in df_finals.columns if col.startswith('product_type_cleaned_')]\n",
        "brand_cols = [col for col in df_finals.columns if col.startswith('broad_type_')]\n",
        "\n",
        "# Add edges for material, category, and brand similarity\n",
        "for feature_group in [material_cols, category_cols, brand_cols]:\n",
        "    add_edges_by_feature_block(feature_group)\n",
        "\n",
        "# Add engagement-based edges using nearest neighbors on the number of likes\n",
        "likes = df_finals[numerical_features].values.reshape(-1, 1)\n",
        "nn_engagement = NearestNeighbors(n_neighbors=6, algorithm='auto', metric='euclidean')\n",
        "nn_engagement.fit(likes)\n",
        "_, indices = nn_engagement.kneighbors(likes)\n",
        "\n",
        "row_indices.extend(np.repeat(np.arange(num_nodes), 5))  # skip self-loop\n",
        "col_indices.extend(indices[:, 1:].flatten())\n",
        "\n",
        "# Combine all into a sparse COO matrix to remove duplicates efficiently\n",
        "edge_matrix = coo_matrix((np.ones(len(row_indices)), (row_indices, col_indices)), shape=(num_nodes, num_nodes))\n",
        "edge_matrix.setdiag(0)  # remove self-loops if any\n",
        "edge_matrix.eliminate_zeros()\n",
        "\n",
        "# Convert to edge index for PyTorch Geometric\n",
        "edge_index = torch.tensor(np.vstack((edge_matrix.row, edge_matrix.col)), dtype=torch.long)\n",
        "\n",
        "# Create the PyTorch Geometric Data object\n",
        "data = Data(x=x, edge_index=edge_index, y=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbXxJT6ON_so"
      },
      "source": [
        "## Dataset Split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = data.num_nodes\n",
        "indices = torch.randperm(num_nodes)\n",
        "train_size = int(0.8 * num_nodes)\n",
        "\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "train_mask[indices[:train_size]] = True\n",
        "test_mask[indices[train_size:]] = True\n",
        "\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask"
      ],
      "metadata": {
        "id": "9qPzsGDuTOwJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FySTfRpWNBHX"
      },
      "source": [
        "## Model Strucuture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qnykfygdNBHX"
      },
      "outputs": [],
      "source": [
        "class GNNPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, model_type='GCN'):\n",
        "        super(GNNPredictor, self).__init__()\n",
        "\n",
        "        if model_type == 'GCN':\n",
        "            self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "            self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        elif model_type == 'SAGE':\n",
        "            self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "            self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "        elif model_type == 'GAT2':\n",
        "            self.conv1 = GATv2Conv(in_channels, hidden_channels)\n",
        "            self.conv2 = GATv2Conv(hidden_channels, out_channels)\n",
        "\n",
        "        # Final regressor\n",
        "        self.value_predict = nn.Sequential(\n",
        "            nn.Linear(out_channels, hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden_channels, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        out = self.value_predict(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TISOqUNp2FG5"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MTN28lTndIqY"
      },
      "outputs": [],
      "source": [
        "def train_model(model, data, train_mask, optimizer, epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index).squeeze()\n",
        "        loss = F.mse_loss(out[train_mask], data.y[train_mask].squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (epoch+1) % 20 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixHh1W032FG6"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v8jkTd332FG6"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data, test_mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(data.x, data.edge_index).squeeze()\n",
        "        true = data.y[test_mask].squeeze()\n",
        "        pred = pred[test_mask]\n",
        "        mse = F.mse_loss(pred, true).item()\n",
        "        mae = F.l1_loss(pred, true).item()\n",
        "        r2 = 1 - ((true - pred) ** 2).sum() / ((true - true.mean()) ** 2).sum()\n",
        "        return {'mse': mse, 'mae': mae, 'r2': r2.item()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiRrKblBOSbN"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = data.to(device)\n",
        "\n",
        "model = GNNPredictor(\n",
        "    in_channels=data.num_features,\n",
        "    hidden_channels=64,\n",
        "    out_channels=32,\n",
        "    model_type='GCN'\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "# Train and evaluate\n",
        "model = train_model(model, data, data.train_mask, optimizer, epochs=100)\n",
        "results = evaluate_model(model, data, data.test_mask)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(f\"MSE: {results['mse']:.4f}\")\n",
        "print(f\"MAE: {results['mae']:.4f}\")\n",
        "print(f\"R²: {results['r2']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfmspHztTbMY",
        "outputId": "c473d227-42fd-4c9d-8375-fe4443ffb52c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 1007951.8125\n",
            "Epoch 40, Loss: 963432.8125\n",
            "Epoch 60, Loss: 934986.1875\n",
            "Epoch 80, Loss: 909563.8750\n",
            "Epoch 100, Loss: 886319.5625\n",
            "Test Results:\n",
            "MSE: 644539.8125\n",
            "MAE: 355.7698\n",
            "R²: 0.0546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GNNPredictor(\n",
        "    in_channels=data.num_features,\n",
        "    hidden_channels=64,\n",
        "    out_channels=32,\n",
        "    model_type='SAGE'\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "# Train and evaluate\n",
        "model = train_model(model, data, data.train_mask, optimizer, epochs=100)\n",
        "results = evaluate_model(model, data, data.test_mask)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(f\"MSE: {results['mse']:.4f}\")\n",
        "print(f\"MAE: {results['mae']:.4f}\")\n",
        "print(f\"R²: {results['r2']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Zp4FOUV13x",
        "outputId": "5b602527-55db-4072-a9a8-8b1f52f1a14d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 973780.4375\n",
            "Epoch 40, Loss: 879697.6875\n",
            "Epoch 60, Loss: 794679.6250\n",
            "Epoch 80, Loss: 690361.5000\n",
            "Epoch 100, Loss: 625615.8750\n",
            "Test Results:\n",
            "MSE: 455572.8750\n",
            "MAE: 283.8397\n",
            "R²: 0.3318\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}